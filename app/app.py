"""
Application Streamlit pour la DÃ©tection de Somnolence.

Interface web interactive permettant:
- Upload d'images/vidÃ©os pour analyse
- DÃ©tection en temps rÃ©el via webcam
- Visualisation des mÃ©triques
- Historique des alertes
"""

import os
import sys
import io
import base64
import tempfile
from datetime import datetime

import streamlit as st
import cv2
import numpy as np
from PIL import Image

# Ajout du path source
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from detection.landmark_extractor import LandmarkExtractor
from utils.preprocessing import ImagePreprocessor
from utils.metrics import FatigueMetrics, calculate_ear, calculate_mar

# Import conditionnel des modÃ¨les (Ã©vite erreurs si TensorFlow non installÃ©)
try:
    from models.cnn import EyeCNN
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False
    EyeCNN = None


# Configuration de la page
st.set_page_config(
    page_title="DÃ©tection de Somnolence | Driver Drowsiness",
    page_icon="ğŸš—",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Styles CSS personnalisÃ©s
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #FF6B6B;
        text-align: center;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 1rem;
        text-align: center;
    }
    .alert-box {
        background-color: #ffebee;
        border-left: 5px solid #f44336;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #e8f5e9;
        border-left: 5px solid #4caf50;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .stProgress > div > div > div > div {
        background-color: #FF6B6B;
    }
</style>
""", unsafe_allow_html=True)


def get_image_download_link(img, filename, text):
    """GÃ©nÃ¨re un lien de tÃ©lÃ©chargement pour une image."""
    buffered = io.BytesIO()
    img.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    href = f'<a href="data:file/png;base64,{img_str}" download="{filename}">{text}</a>'
    return href


def process_image(image: np.ndarray, 
                  landmark_extractor: LandmarkExtractor,
                  fatigue_metrics: FatigueMetrics) -> tuple:
    """
    Traite une image et retourne les rÃ©sultats.
    
    Returns:
        tuple: (image_annotÃ©e, ear, mar, alerts, face_detected)
    """
    result_image = image.copy()
    
    # DÃ©tection
    face_detected = landmark_extractor.process(image)
    
    ear = 0.0
    mar = 0.0
    alerts = {}
    
    if face_detected:
        # Extraction des landmarks
        left_eye_pts, right_eye_pts = landmark_extractor.get_eye_landmarks(image.shape)
        mouth_pts = landmark_extractor.get_mouth_landmarks(image.shape)
        
        # Calcul EAR
        if left_eye_pts and right_eye_pts:
            ear_left = calculate_ear(left_eye_pts)
            ear_right = calculate_ear(right_eye_pts)
            ear = (ear_left + ear_right) / 2
        
        # Calcul MAR
        if mouth_pts:
            mar = calculate_mar(mouth_pts)
        
        # Mise Ã  jour des mÃ©triques
        alerts = fatigue_metrics.update(ear, mar)
        
        # Dessin des landmarks
        result_image = landmark_extractor.draw_landmarks(image)
    
    return result_image, ear, mar, alerts, face_detected


def render_header():
    """Affiche l'en-tÃªte de l'application."""
    st.markdown('<p class="main-header">ğŸš— DÃ©tection de Somnolence</p>', 
                unsafe_allow_html=True)
    st.markdown('<p class="sub-header">SystÃ¨me de surveillance du conducteur par Deep Learning</p>', 
                unsafe_allow_html=True)


def render_sidebar():
    """Affiche la barre latÃ©rale."""
    with st.sidebar:
        st.header("âš™ï¸ Configuration")
        
        # Seuils
        st.subheader("Seuils de dÃ©tection")
        ear_threshold = st.slider("Seuil EAR", 0.1, 0.4, 0.25, 0.01,
                                  help="Eye Aspect Ratio threshold")
        mar_threshold = st.slider("Seuil MAR", 0.3, 1.0, 0.6, 0.05,
                                  help="Mouth Aspect Ratio threshold")
        
        # Mode d'analyse
        st.subheader("Mode d'analyse")
        analysis_mode = st.radio(
            "SÃ©lectionnez le mode:",
            ["ğŸ“· Image", "ğŸ¥ VidÃ©o", "ğŸ“¹ Webcam"]
        )
        
        # Informations
        st.markdown("---")
        st.subheader("â„¹ï¸ Informations")
        st.markdown("""
        **MÃ©triques:**
        - **EAR**: Eye Aspect Ratio
        - **MAR**: Mouth Aspect Ratio
        - **PERCLOS**: % fermeture des yeux
        
        **Auteur:** SDIA Student
        **Version:** 1.0.0
        """)
        
        return ear_threshold, mar_threshold, analysis_mode


def render_image_analysis(ear_threshold: float, mar_threshold: float):
    """Affiche l'analyse d'image."""
    st.header("ğŸ“· Analyse d'Image")
    
    uploaded_file = st.file_uploader(
        "Choisissez une image",
        type=['png', 'jpg', 'jpeg'],
        help="TÃ©lÃ©chargez une image contenant un visage"
    )
    
    if uploaded_file is not None:
        # Chargement de l'image
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
        
        # Initialisation
        landmark_extractor = LandmarkExtractor(static_image_mode=True)
        fatigue_metrics = FatigueMetrics(
            ear_threshold=ear_threshold,
            mar_threshold=mar_threshold
        )
        
        # Traitement
        with st.spinner("Analyse en cours..."):
            result_image, ear, mar, alerts, face_detected = process_image(
                image, landmark_extractor, fatigue_metrics
            )
        
        # Affichage des rÃ©sultats
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Image Originale")
            st.image(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), use_column_width=True)
        
        with col2:
            st.subheader("RÃ©sultat de l'Analyse")
            st.image(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB), use_column_width=True)
        
        # MÃ©triques
        if face_detected:
            st.markdown("---")
            st.subheader("ğŸ“Š MÃ©triques de Fatigue")
            
            metrics_col1, metrics_col2, metrics_col3 = st.columns(3)
            
            with metrics_col1:
                ear_color = "normal" if ear > ear_threshold else "off"
                st.metric(
                    "Eye Aspect Ratio (EAR)",
                    f"{ear:.3f}",
                    delta="Ouvert" if ear > ear_threshold else "FermÃ©",
                    delta_color=ear_color
                )
            
            with metrics_col2:
                mar_color = "off" if mar > mar_threshold else "normal"
                st.metric(
                    "Mouth Aspect Ratio (MAR)",
                    f"{mar:.3f}",
                    delta="BÃ¢illement" if mar > mar_threshold else "Normal",
                    delta_color=mar_color
                )
            
            with metrics_col3:
                stats = fatigue_metrics.get_statistics()
                perclos = stats['perclos']
                st.metric(
                    "PERCLOS",
                    f"{perclos*100:.1f}%",
                    delta="Alerte" if perclos > 0.15 else "OK",
                    delta_color="off" if perclos > 0.15 else "normal"
                )
            
            # Alertes
            if any(alerts.values()):
                st.markdown('<div class="alert-box">', unsafe_allow_html=True)
                st.error("âš ï¸ **ALERTE: Fatigue dÃ©tectÃ©e!**")
                if alerts['eye_closure']:
                    st.write("- ğŸš« Yeux fermÃ©s prolongÃ©s")
                if alerts['yawn']:
                    st.write("- ğŸ¥± BÃ¢illement dÃ©tectÃ©")
                if alerts['drowsiness_alert']:
                    st.write("- âš¡ Risque de somnolence Ã©levÃ©")
                st.markdown('</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="success-box">', unsafe_allow_html=True)
                st.success("âœ… Ã‰tat normal - Aucune fatigue dÃ©tectÃ©e")
                st.markdown('</div>', unsafe_allow_html=True)
        else:
            st.warning("âš ï¸ Aucun visage dÃ©tectÃ© dans l'image")


def render_video_analysis(ear_threshold: float, mar_threshold: float):
    """Affiche l'analyse vidÃ©o."""
    st.header("ğŸ¥ Analyse VidÃ©o")
    
    uploaded_file = st.file_uploader(
        "Choisissez une vidÃ©o",
        type=['mp4', 'avi', 'mov'],
        help="TÃ©lÃ©chargez une vidÃ©o pour analyse"
    )
    
    if uploaded_file is not None:
        st.info("ğŸ¬ Traitement de la vidÃ©o...")
        
        # Sauvegarde temporaire
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        tfile.write(uploaded_file.read())
        
        # Affichage de la vidÃ©o originale
        st.video(tfile.name)
        
        st.warning("""
        ğŸ’¡ **Note:** Le traitement vidÃ©o complet peut prendre du temps.
        Pour une dÃ©monstration en temps rÃ©el, utilisez le mode Webcam.
        """)


def render_webcam_analysis(ear_threshold: float, mar_threshold: float):
    """Affiche l'analyse webcam en temps rÃ©el."""
    st.header("ğŸ“¹ DÃ©tection en Temps RÃ©el")
    
    st.info("""
    ğŸ“¸ **Mode Webcam**
    
    Cliquez sur "DÃ©marrer la camÃ©ra" pour lancer la dÃ©tection en temps rÃ©el.
    Assurez-vous que votre webcam est connectÃ©e.
    """)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # Bouton pour dÃ©marrer
        run_camera = st.checkbox("â–¶ï¸ DÃ©marrer la camÃ©ra")
        
        if run_camera:
            # Placeholder pour la vidÃ©o
            frame_placeholder = st.empty()
            
            # Initialisation
            landmark_extractor = LandmarkExtractor(static_image_mode=False)
            fatigue_metrics = FatigueMetrics(
                ear_threshold=ear_threshold,
                mar_threshold=mar_threshold
            )
            
            # Ouverture de la camÃ©ra
            cap = cv2.VideoCapture(0)
            
            try:
                while run_camera:
                    ret, frame = cap.read()
                    
                    if not ret:
                        st.error("âŒ Erreur: Impossible d'accÃ©der Ã  la webcam")
                        break
                    
                    # Traitement
                    result_frame, ear, mar, alerts, face_detected = process_image(
                        frame, landmark_extractor, fatigue_metrics
                    )
                    
                    # Affichage
                    frame_placeholder.image(
                        cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB),
                        channels="RGB",
                        use_column_width=True
                    )
                    
                    # Mise Ã  jour des mÃ©triques
                    if face_detected:
                        st.session_state['current_ear'] = ear
                        st.session_state['current_mar'] = mar
                        st.session_state['current_alerts'] = alerts
            
            finally:
                cap.release()
                landmark_extractor.close()
    
    with col2:
        st.subheader("ğŸ“Š MÃ©triques en Direct")
        
        # MÃ©triques actuelles
        if 'current_ear' in st.session_state:
            ear = st.session_state['current_ear']
            mar = st.session_state['current_mar']
            alerts = st.session_state['current_alerts']
            
            # Jauges
            st.write("**Eye Aspect Ratio (EAR)**")
            st.progress(min(ear / 0.5, 1.0))
            st.write(f"Valeur: {ear:.3f}")
            
            st.write("**Mouth Aspect Ratio (MAR)**")
            st.progress(min(mar / 1.0, 1.0))
            st.write(f"Valeur: {mar:.3f}")
            
            # Ã‰tat
            if any(alerts.values()):
                st.error("âš ï¸ **ALERTE!**")
            else:
                st.success("âœ… **Normal**")
        else:
            st.write("*En attente de donnÃ©es...*")
        
        # Instructions
        st.markdown("---")
        st.subheader("ğŸ® ContrÃ´les")
        st.write("- DÃ©cochez pour arrÃªter")
        st.write("- Positionnez-vous face Ã  la camÃ©ra")
        st.write("- Assurez un Ã©clairage adÃ©quat")


def render_about():
    """Affiche la page Ã  propos."""
    st.header("ğŸ“š Ã€ Propos du Projet")
    
    st.markdown("""
    ## Vision par Ordinateur et Deep Learning
    
    Ce projet implÃ©mente un systÃ¨me de **dÃ©tection de somnolence du conducteur**
    utilisant des techniques de Deep Learning et de vision par ordinateur.
    
    ### ğŸ§  Concepts du Cours AppliquÃ©s
    
    **Chapitre 1 - Fondamentaux:**
    - Perceptron et classification binaire
    - Fonction sigmoÃ¯de et activation
    - Descente de gradient
    - Fonction de perte (Binary Cross-Entropy)
    
    **Chapitre 2 - PMC:**
    - RÃ©seaux multi-couches
    - Forward et Backward propagation
    - RÃ©gularisation (Dropout)
    
    **Chapitre 3-4 - CNN:**
    - Convolution et extraction de features
    - Max Pooling
    - Transfer Learning (MobileNetV2)
    - Data Augmentation
    
    ### ğŸ”§ Architecture du SystÃ¨me
    
    ```
    Webcam â†’ DÃ©tection Visage â†’ Landmarks (MediaPipe)
                                     â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  EAR (Eye Aspect Ratio)                             â”‚
    â”‚  MAR (Mouth Aspect Ratio)                           â”‚
    â”‚  PERCLOS (% fermeture des yeux)                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
            Classification Fatigue
                     â†“
               Alerte Conducteur
    ```
    
    ### ğŸ“Š MÃ©triques UtilisÃ©es
    
    | MÃ©trique | Description | Seuil |
    |----------|-------------|-------|
    | EAR | Ratio d'aspect de l'Å“il | < 0.25 |
    | MAR | Ratio d'aspect de la bouche | > 0.6 |
    | PERCLOS | % temps yeux fermÃ©s | > 15% |
    
    ### ğŸ› ï¸ Technologies
    
    - **TensorFlow/Keras**: Deep Learning
    - **OpenCV**: Vision par ordinateur
    - **MediaPipe**: DÃ©tection faciale
    - **Streamlit**: Interface web
    - **NumPy/Pandas**: Traitement de donnÃ©es
    """)


def main():
    """Point d'entrÃ©e principal."""
    # En-tÃªte
    render_header()
    
    # Barre latÃ©rale
    ear_threshold, mar_threshold, analysis_mode = render_sidebar()
    
    # Contenu principal
    if analysis_mode == "ğŸ“· Image":
        render_image_analysis(ear_threshold, mar_threshold)
    
    elif analysis_mode == "ğŸ¥ VidÃ©o":
        render_video_analysis(ear_threshold, mar_threshold)
    
    elif analysis_mode == "ğŸ“¹ Webcam":
        render_webcam_analysis(ear_threshold, mar_threshold)
    
    # Pied de page
    st.markdown("---")
    st.markdown(
        "<p style='text-align: center; color: #888;'>"
        "DÃ©veloppÃ© pour le cours de Deep Learning - SDIA | 2024"
        "</p>",
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()
