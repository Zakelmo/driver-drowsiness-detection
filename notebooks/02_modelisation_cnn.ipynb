{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod√©lisation CNN pour la D√©tection de Somnolence\n",
    "\n",
    "## Construction et Entra√Ænement de R√©seaux de Neurones Convolutifs\n",
    "\n",
    "Ce notebook couvre:\n",
    "1. **Construction du CNN from scratch**\n",
    "2. **Entra√Ænement avec callbacks**\n",
    "3. **Transfer Learning** avec MobileNetV2\n",
    "4. **√âvaluation et Visualisation des r√©sultats**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# V√©rification GPU\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Ajout du path source\n",
    "sys.path.append('../src')\n",
    "from models.cnn import EyeCNN, YawnCNN\n",
    "from models.transfer_learning import TransferLearningModel\n",
    "from utils.metrics import ModelMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des donn√©es pr√©trait√©es\n",
    "DATA_DIR = '../data/processed'\n",
    "\n",
    "X_train = np.load(f'{DATA_DIR}/X_train.npy')\n",
    "X_val = np.load(f'{DATA_DIR}/X_val.npy')\n",
    "X_test = np.load(f'{DATA_DIR}/X_test.npy')\n",
    "y_train = np.load(f'{DATA_DIR}/y_train.npy')\n",
    "y_val = np.load(f'{DATA_DIR}/y_val.npy')\n",
    "y_test = np.load(f'{DATA_DIR}/y_test.npy')\n",
    "\n",
    "print(\"Donn√©es charg√©es:\")\n",
    "print(f\"  Train: {X_train.shape}, Labels: {y_train.shape}\")\n",
    "print(f\"  Val:   {X_val.shape}, Labels: {y_val.shape}\")\n",
    "print(f\"  Test:  {X_test.shape}, Labels: {y_test.shape}\")\n",
    "print(f\"\\nDistribution - Train: {np.bincount(y_train)}, Val: {np.bincount(y_val)}, Test: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construction du CNN (From Scratch)\n",
    "\n",
    "### 3.1 Architecture du Mod√®le\n",
    "\n",
    "Le CNN pour la d√©tection des yeux suit l'architecture classique:\n",
    "- **Input**: Images 48x48 en niveaux de gris\n",
    "- **Conv + Pool**: Extraction de features\n",
    "- **Flatten**: Aplatissement\n",
    "- **Dense + Dropout**: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation du mod√®le CNN\n",
    "cnn_model = EyeCNN(config_path='../config.yaml')\n",
    "model = cnn_model.build_model()\n",
    "\n",
    "# Affichage du r√©sum√©\n",
    "print(\"=\"*60)\n",
    "print(\"ARCHITECTURE DU CNN POUR D√âTECTION DES YEUX\")\n",
    "print(\"=\"*60)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualisation de l'Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'architecture\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='../reports/figures/cnn_architecture.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=True\n",
    ")\n",
    "\n",
    "print(\"‚úì Sch√©ma de l'architecture sauvegard√©\")\n",
    "\n",
    "# Affichage des dimensions de sortie de chaque couche\n",
    "print(\"\\nDimensions des tenseurs par couche:\")\n",
    "print(\"-\"*60)\n",
    "for layer in model.layers:\n",
    "    print(f\"{layer.name:20s} -> {layer.output_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entra√Ænement du Mod√®le\n",
    "\n",
    "### 4.1 Callbacks pour l'Entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des callbacks\n",
    "callbacks_list = [\n",
    "    # Early Stopping: arr√™te si pas d'am√©lioration apr√®s 10 √©poques\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Model Checkpoint: sauvegarde le meilleur mod√®le\n",
    "    callbacks.ModelCheckpoint(\n",
    "        '../models/cnn_eye_best.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce LR: r√©duit le learning rate si plateau\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # TensorBoard: visualisation\n",
    "    callbacks.TensorBoard(\n",
    "        log_dir='../reports/logs',\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configur√©s:\")\n",
    "for cb in callbacks_list:\n",
    "    print(f\"  - {cb.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Lancement de l'Entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param√®tres d'entra√Ænement\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"D√âBUT DE L'ENTRA√éNEMENT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs max: {EPOCHS}\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Entra√Ænement\n",
    "history = cnn_model.train(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Entra√Ænement termin√©!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Visualisation de l'Entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'historique d'entra√Ænement\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history.history['loss'], label='Train', linewidth=2)\n",
    "axes[0, 0].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[0, 0].set_title('Loss (Binary Cross-Entropy)', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "axes[0, 1].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[0, 1].set_title('Accuracy', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision\n",
    "axes[1, 0].plot(history.history['precision'], label='Train', linewidth=2)\n",
    "axes[1, 0].plot(history.history['val_precision'], label='Validation', linewidth=2)\n",
    "axes[1, 0].set_title('Precision', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Precision')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# AUC\n",
    "axes[1, 1].plot(history.history['auc'], label='Train', linewidth=2)\n",
    "axes[1, 1].plot(history.history['val_auc'], label='Validation', linewidth=2)\n",
    "axes[1, 1].set_title('AUC-ROC', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('AUC')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Historique d\\'Entra√Ænement du CNN', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Affichage des meilleurs scores\n",
    "print(\"\\nMeilleurs scores sur validation:\")\n",
    "print(\"-\"*40)\n",
    "best_epoch = np.argmax(history.history['val_accuracy'])\n",
    "print(f\"Epoch: {best_epoch + 1}\")\n",
    "print(f\"Accuracy: {history.history['val_accuracy'][best_epoch]:.4f}\")\n",
    "print(f\"Precision: {history.history['val_precision'][best_epoch]:.4f}\")\n",
    "print(f\"AUC: {history.history['val_auc'][best_epoch]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. √âvaluation sur le Jeu de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âvaluation\n",
    "print(\"=\"*60)\n",
    "print(\"√âVALUATION SUR LE JEU DE TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_loss, test_acc, test_prec, test_rec, test_auc = model.evaluate(\n",
    "    X_test, y_test, verbose=0\n",
    ")\n",
    "\n",
    "print(f\"Loss: {test_loss:.4f}\")\n",
    "print(f\"Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Precision: {test_prec:.4f}\")\n",
    "print(f\"Recall: {test_rec:.4f}\")\n",
    "print(f\"AUC: {test_auc:.4f}\")\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"\\nRapport de Classification:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred, \n",
    "                           target_names=['Ouvert (0)', 'Ferm√© (1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Matrice de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=['Ouvert', 'Ferm√©'],\n",
    "           yticklabels=['Ouvert', 'Ferm√©'],\n",
    "           ax=axes[0])\n",
    "axes[0].set_title('Matrice de Confusion', fontweight='bold')\n",
    "axes[0].set_xlabel('Pr√©dit')\n",
    "axes[0].set_ylabel('R√©el')\n",
    "\n",
    "# Normalis√©e\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Blues',\n",
    "           xticklabels=['Ouvert', 'Ferm√©'],\n",
    "           yticklabels=['Ouvert', 'Ferm√©'],\n",
    "           ax=axes[1])\n",
    "axes[1].set_title('Matrice de Confusion (Normalis√©e)', fontweight='bold')\n",
    "axes[1].set_xlabel('Pr√©dit')\n",
    "axes[1].set_ylabel('R√©el')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calcul des m√©triques d√©taill√©es\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nD√©tail des pr√©dictions:\")\n",
    "print(f\"  Vrais N√©gatifs (TN): {tn}\")\n",
    "print(f\"  Faux Positifs (FP):  {fp}\")\n",
    "print(f\"  Faux N√©gatifs (FN):  {fn}\")\n",
    "print(f\"  Vrais Positifs (TP): {tp}\")\n",
    "print(f\"\\nSpecificity (TNR): {tn/(tn+fp):.4f}\")\n",
    "print(f\"Sensitivity (TPR): {tp/(tp+fn):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Courbe ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "        label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', \n",
    "        label='Random classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux de Faux Positifs (FPR)', fontsize=12)\n",
    "plt.ylabel('Taux de Vrais Positifs (TPR)', fontsize=12)\n",
    "plt.title('Courbe ROC - Classification des Yeux', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('../reports/figures/roc_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transfer Learning avec MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Pr√©paration des Donn√©es RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion en RGB 224x224 pour Transfer Learning\n",
    "def prepare_for_transfer(X, y):\n",
    "    \"\"\"Pr√©pare les donn√©es pour MobileNetV2.\"\"\"\n",
    "    X_rgb = []\n",
    "    for img in X:\n",
    "        # Convertir en 3 canaux\n",
    "        img_3ch = np.repeat(img, 3, axis=-1)\n",
    "        # Redimensionner\n",
    "        img_resized = tf.image.resize(img_3ch, [224, 224])\n",
    "        # Normalisation [-1, 1] pour MobileNetV2\n",
    "        img_norm = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
    "            img_resized * 255\n",
    "        )\n",
    "        X_rgb.append(img_norm)\n",
    "    return np.array(X_rgb), y\n",
    "\n",
    "print(\"Pr√©paration des donn√©es pour Transfer Learning...\")\n",
    "X_train_tl, y_train_tl = prepare_for_transfer(X_train, y_train)\n",
    "X_val_tl, y_val_tl = prepare_for_transfer(X_val, y_val)\n",
    "X_test_tl, y_test_tl = prepare_for_transfer(X_test, y_test)\n",
    "\n",
    "print(f\"Train: {X_train_tl.shape}\")\n",
    "print(f\"Val: {X_val_tl.shape}\")\n",
    "print(f\"Test: {X_test_tl.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Construction du Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation du mod√®le de Transfer Learning\n",
    "print(\"=\"*60)\n",
    "print(\"TRANSFER LEARNING - MobileNetV2\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "transfer_model = TransferLearningModel(\n",
    "    base_model_name=\"MobileNetV2\",\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Phase 1: Feature Extraction\n",
    "model_tl = transfer_model.build_feature_extractor(trainable=False)\n",
    "\n",
    "print(\"\\nArchitecture du mod√®le de Transfer Learning:\")\n",
    "model_tl.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Entra√Ænement (Phase 1 - Feature Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænement Phase 1\n",
    "history_tl = transfer_model.train(\n",
    "    X_train=X_train_tl,\n",
    "    y_train=y_train_tl,\n",
    "    X_val=X_val_tl,\n",
    "    y_val=y_val_tl,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    fine_tune=False\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Phase 1 (Feature Extraction) termin√©e!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Fine-Tuning (Phase 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Fine-tuning\n",
    "print(\"\\n=\"*60)\n",
    "print(\"PHASE 2: FINE-TUNING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "history_fine = transfer_model.train(\n",
    "    X_train=X_train_tl,\n",
    "    y_train=y_train_tl,\n",
    "    X_val=X_val_tl,\n",
    "    y_val=y_val_tl,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    fine_tune=True,\n",
    "    fine_tune_epochs=10\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Fine-tuning termin√©!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Comparaison des Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âvaluation du mod√®le Transfer Learning\n",
    "test_loss_tl, test_acc_tl, test_prec_tl, test_rec_tl, test_auc_tl = model_tl.evaluate(\n",
    "    X_test_tl, y_test_tl, verbose=0\n",
    ")\n",
    "\n",
    "# Comparaison\n",
    "comparison = {\n",
    "    'M√©trique': ['Accuracy', 'Precision', 'Recall', 'AUC'],\n",
    "    'CNN from Scratch': [test_acc, test_prec, test_rec, test_auc],\n",
    "    'MobileNetV2 (TL)': [test_acc_tl, test_prec_tl, test_rec_tl, test_auc_tl]\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "df_comparison = pd.DataFrame(comparison)\n",
    "\n",
    "print(\"\\nComparaison des Mod√®les:\")\n",
    "print(\"=\"*60)\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# Visualisation\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(df_comparison))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, df_comparison['CNN from Scratch'], width, \n",
    "               label='CNN from Scratch', color='skyblue', edgecolor='black')\n",
    "bars2 = ax.bar(x + width/2, df_comparison['MobileNetV2 (TL)'], width,\n",
    "               label='MobileNetV2 (TL)', color='lightcoral', edgecolor='black')\n",
    "\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Comparaison des Mod√®les', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_comparison['M√©trique'])\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 1])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Ajouter les valeurs\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualisation des Pr√©dictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des pr√©dictions\n",
    "n_samples = 12\n",
    "indices = np.random.choice(len(X_test), n_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    img = X_test[idx].squeeze()\n",
    "    true_label = y_test[idx]\n",
    "    pred_proba = y_pred_proba[idx][0]\n",
    "    pred_label = int(pred_proba > 0.5)\n",
    "    \n",
    "    # Couleur selon la pr√©diction\n",
    "    if pred_label == true_label:\n",
    "        color = 'green'\n",
    "        border_color = '#2ecc71'\n",
    "    else:\n",
    "        color = 'red'\n",
    "        border_color = '#e74c3c'\n",
    "    \n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].set_title(\n",
    "        f'R√©el: {\"Ferm√©\" if true_label else \"Ouvert\"}\\n'\n",
    "        f'Pr√©dit: {\"Ferm√©\" if pred_label else \"Ouvert\"} ({pred_proba:.2f})',\n",
    "        color=color, fontweight='bold'\n",
    "    )\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    # Bordure color√©e\n",
    "    for spine in axes[i].spines.values():\n",
    "        spine.set_edgecolor(border_color)\n",
    "        spine.set_linewidth(3)\n",
    "\n",
    "plt.suptitle('Pr√©dictions sur le Jeu de Test', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sauvegarde des Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des mod√®les\n",
    "print(\"Sauvegarde des mod√®les...\")\n",
    "\n",
    "# CNN from scratch\n",
    "model.save('../models/cnn_eye_final.h5')\n",
    "print(\"‚úì CNN sauvegard√©: models/cnn_eye_final.h5\")\n",
    "\n",
    "# Transfer Learning\n",
    "model_tl.save('../models/mobilenet_fatigue_final.h5')\n",
    "print(\"‚úì MobileNetV2 sauvegard√©: models/mobilenet_fatigue_final.h5\")\n",
    "\n",
    "# Historiques\n",
    "import pickle\n",
    "with open('../models/history_cnn.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "with open('../models/history_transfer.pkl', 'wb') as f:\n",
    "    pickle.dump(history_tl.history, f)\n",
    "print(\"‚úì Historiques sauvegard√©s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MOD√àLES ENTRAIN√âS ET SAUVEGARD√âS AVEC SUCC√àS!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. R√©sum√© et Prochaines √âtapes\n",
    "\n",
    "### Concepts du Cours Appliqu√©s\n",
    "\n",
    "- ‚úÖ **Chapitre 1**: Fonction de perte, optimisation\n",
    "- ‚úÖ **Chapitre 2**: MLP, r√©gularisation (Dropout)\n",
    "- ‚úÖ **Chapitre 3-4**: CNN, Transfer Learning, Data Augmentation\n",
    "\n",
    "### Prochaine √âtape\n",
    "\n",
    "Le notebook suivant (03_evaluation_et_tests.ipynb) couvrira:\n",
    "- Tests sur donn√©es r√©elles\n",
    "- Optimisation pour d√©ploiement\n",
    "- Int√©gration temps r√©el\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook 02 termin√©!** üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
